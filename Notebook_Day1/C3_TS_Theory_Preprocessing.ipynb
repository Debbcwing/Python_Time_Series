{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88d499fb-f4a0-420a-bd70-7fd16515cb5f",
   "metadata": {},
   "source": [
    "<img src=\"../Images/DSC_Logo.png\" style=\"width: 400px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d42ef55-b242-4201-99ab-12978da76a6c",
   "metadata": {},
   "source": [
    "# Time Series Theory in Python - Part 3: Time Series Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4548cbc1-1c5e-4b9d-9c26-ad3403c344dc",
   "metadata": {},
   "source": [
    "This notebook presents several techniques for time series preprocessing, which are crucial for preparing data for analysis and predictive modeling. These techniques can serve as independent analyses on their own and facilitate further preprocessing tailored to specific prediction tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b20d62b-a59e-473d-ab67-8921d9d4567f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip install statsmodels PythonTsa statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c735a549-1ab1-400a-b609-0f2c39866698",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12d913a-e9c5-4bd4-88cb-5be568b15c3f",
   "metadata": {},
   "source": [
    "## 1. Smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff78867f-22ec-403a-a277-876e39410651",
   "metadata": {},
   "source": [
    "### **Example 1: Australian Employed Total Persons**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03c19bf-4130-4137-90f0-4026d1f9feb5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get the data file path\n",
    "dtapath = getdtapath()\n",
    "\n",
    "# Load the Excel file containing employment data\n",
    "aul = pd.read_excel(dtapath + 'AustraliaEmployedTotalPersons.xlsx', header=0)\n",
    "\n",
    "# Apply smoothing using a moving average\n",
    "window_size = 12  # Define the window size for moving average (e.g., 12 for yearly smoothing)\n",
    "y_smoothed = pd.Series(y).rolling(window=window_size, center=True).mean().values\n",
    "\n",
    "# Plotting the results\n",
    "plt.figure()\n",
    "plt.scatter(aul.index, y, label='Original Data (Total Employed Persons)', color='gray', alpha=0.5)  # Original data\n",
    "plt.plot(aul.index, y_smoothed, label='Smoothed Data (Moving Average)', color='blue', linewidth=2)  # Smoothed data\n",
    "\n",
    "# Adding titles and labels\n",
    "plt.title('Original and Smoothed Number of Employed Persons in Australia')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Number of Persons Employed')  # Clarified y-axis label\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c83b887-b416-4a52-b6f6-5d9dc862289a",
   "metadata": {},
   "source": [
    "## 2. Detrending"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c938b522-c280-4122-a3b8-f9630ff99921",
   "metadata": {},
   "source": [
    "The resulting detrended data represents the deviations from the trend. The values in the detrended series indicate how much each observation is above or below the trend line. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7efc89-3449-4e9a-8bbb-49ac0b11253c",
   "metadata": {},
   "source": [
    "### **Example 2: Mean Spring Passage Dates of European Pied Flycatcher**\n",
    "\n",
    "The dataset contains the migration data of the European Pied Flycatcher, focusing on the adjusted mean spring passage dates (MADJDAYSWS) across multiple years. The dataset includes annual observations.\n",
    "\n",
    "**Original dataset and code:** Haest, B., Hüppop, O., & Bairlein, F. (2020). Code and data for: \"Weather at the winter and stopover areas determines spring migration onset, progress, and advancements in Afro-Palearctic migrant birds\". In Proceedings of the National Academy of Sciences of the United States of America (v1.0, Bd. 117, Nummer 29, S. 17056–17062). Zenodo. doi:10.5281/zenodo.3629178              \n",
    "\n",
    "**Related publication(s):** Haest, B., Hüppop, O., and Bairlein, F.: Weather at the winter and stopover areas determines spring migration onset, progress, and advancements in Afro-Palearctic migrant birds, Proceedings of the National Academy of Sciences, 117, 17056–17062, doi:10.1073/pnas.1920448117,              2020.\n",
    "\n",
    "Original data and code were modified for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d6d1ef-1f4f-4368-ba6a-b932f7a7d238",
   "metadata": {},
   "outputs": [],
   "source": [
    "bird_migration = pd.read_csv('../Datasets/bird_migration.csv', sep = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43aa860b-25f5-40bb-b96a-9fd74b59e3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# Assuming the 'MADJDAYSWS' is the column you want as y\n",
    "y2 = bird_migration['MADJDAYSWS'].values  # Extracting dependent variable\n",
    "time2 = bird_migration['Year'].values  # Using the Year column as the time variable\n",
    "\n",
    "# Checking the lengths\n",
    "print(f'Length of y: {len(y2)}')\n",
    "print(f'Length of time: {len(time2)}')\n",
    "\n",
    "linear_model = sm.OLS(y2, sm.add_constant(time2)).fit()\n",
    "\n",
    "# Perform linear detrending\n",
    "trend = linear_model.fittedvalues  # This is the linear trend\n",
    "detrended_y = y2 - trend\n",
    "\n",
    "# Plot\n",
    "plt.figure()\n",
    "plt.plot(time2, y2, label='Original Data', color='gray', alpha=0.5)  # Original data\n",
    "plt.plot(time2, trend, label='Linear Trend', color='blue', linewidth=1.5)  # Linear trend\n",
    "plt.plot(time2, detrended_y, label='Detrended Data', color='red', linewidth=1.5)\n",
    "plt.title('Original and Detrended MADJDAYSWS')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('MADJDAYSWS')  # Optionally change to 'Detrended MADJDAYSWS'\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd87f10-3dcb-4048-bf46-4fce52fc9baa",
   "metadata": {},
   "source": [
    "## 3 Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50694b5-f5ba-43e2-a4fd-2916a6930200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data for normalization\n",
    "values = y2.reshape((len(y2), 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59bbcc1-8d36-4d8c-9449-eda785c2e1da",
   "metadata": {},
   "source": [
    "(Reshaping on-dimensional data into a two-dimensional format before scaling is necessary because most preprocessing functions expect input data to have the shape of (n_samples, n_features). This ensures that the data is correctly interpreted as multiple samples of one or more features, allowing for proper scaling and processing during model training.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f1ebce-d1c5-4add-b586-0cd2f0a28632",
   "metadata": {},
   "source": [
    "## 3.1 Normalization\n",
    "\n",
    "$$y = (x - min) / (max - min)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c098aa0-9449-4ea3-89a0-35536909967e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# train the normalization\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler = scaler.fit(values)\n",
    "\n",
    "# normalize the dataset and print the first 5 rows\n",
    "normalized = scaler.transform(values)\n",
    "print(normalized[:5])\n",
    "\n",
    "# inverse transform and print the first 5 rows\n",
    "inversed = scaler.inverse_transform(normalized)\n",
    "print(inversed[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9c29c7-883d-488a-83b5-4550511b1a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Min value normalized:\", min(normalized))\n",
    "print(\"Max value normalized:\", max(normalized))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ddcf9c6-b820-496e-b3ac-2e7c917ca16e",
   "metadata": {},
   "source": [
    "## 3.2 Standardization\n",
    "\n",
    "$$y = (x - mean) / std$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d88d95c-73f0-438e-8f06-32804c80f03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from math import sqrt\n",
    "\n",
    "# train the standardization\n",
    "scaler = StandardScaler()\n",
    "scaler = scaler.fit(values)\n",
    "\n",
    "# standardization the dataset and print the first 5 rows\n",
    "normalized = scaler.transform(values)\n",
    "print(normalized[:5])\n",
    "    \n",
    "# inverse transform and print the first 5 rows\n",
    "inversed = scaler.inverse_transform(normalized)\n",
    "print(inversed[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6792ef50-07ec-4f7f-82df-033e36f652f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Min value normalized:\", min(normalized))\n",
    "print(\"Max value normalized:\", max(normalized))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0601ecec-bb3c-45db-b73e-a419800dcbe9",
   "metadata": {},
   "source": [
    "## 4. Outlier/Anomaly Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3d7ba4-7201-4aef-9ff4-3a7354af14d1",
   "metadata": {},
   "source": [
    "### **Example 3: Artificial Streamflow Time Series with Outliers and Change Point**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9d08e6-f200-424c-b075-cc9872952230",
   "metadata": {},
   "source": [
    "We create an artificial time series to simulate the dynamics of streamflow over a defined period while incorporating features like outliers and a change point. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7203000-34d0-4bb7-95e6-b48524f1d783",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "np.random.seed(42)  # For reproducibility\n",
    "days = pd.date_range(start='2021-01-01', end='2023-12-31', freq='D')\n",
    "n = len(days)\n",
    "\n",
    "# Generate a normal streamflow pattern (in m³/s)\n",
    "streamflow = 10 + 0.5 * np.sin(np.linspace(0, 20 * np.pi, n)) + np.random.normal(0, 1, n)\n",
    "\n",
    "# Introduce a change point after 1.5 years (midway through the second year)\n",
    "change_point_index = int(n * 0.75)\n",
    "streamflow[change_point_index:] *= 0.5  # Effect of drying out\n",
    "\n",
    "# Introduce a total of 7 random outliers\n",
    "outliers_indices = np.random.choice(range(n), size=7, replace=False)\n",
    "streamflow[outliers_indices] += np.random.normal(10, 5, size=7)  # Adding outliers above mean\n",
    "\n",
    "# Create a DataFrame\n",
    "data = pd.DataFrame(data={'Date': days, 'Streamflow (m³/s)': streamflow})\n",
    "\n",
    "# Plot the time series\n",
    "plt.figure()\n",
    "plt.plot(data['Date'], data['Streamflow (m³/s)'], label='Streamflow', color='b')\n",
    "plt.axvline(x=data['Date'][change_point_index], color='r', linestyle='--', label='Change Point')\n",
    "plt.plot(data['Date'][outliers_indices], data['Streamflow (m³/s)'][outliers_indices], 'ro', label='Outliers')  # Mark all outliers in red\n",
    "plt.title('Artificial Streamflow Time Series with Outliers and Change Point')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Streamflow (m³/s)')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c007b30-9dc5-4fd3-9700-79654f0dff96",
   "metadata": {},
   "source": [
    "## 4.1 Z-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86566b51-228c-4477-ad15-b5290d25a205",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mean = np.mean(streamflow)\n",
    "std_dev = np.std(streamflow)\n",
    "z_scores = (streamflow - mean) / std_dev\n",
    "outliers_z = np.where(np.abs(z_scores) > 3)[0]\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(data['Date'], data['Streamflow (m³/s)'], label='Streamflow', color='b')\n",
    "plt.scatter(data['Date'][outliers_z], streamflow[outliers_z], color='red', label='Z-score Outliers', zorder=5)\n",
    "plt.title('Z-Score Method for Outlier Detection')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Streamflow (m³/s)')\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd170f22-d422-4773-a1c5-67ba195dae7e",
   "metadata": {},
   "source": [
    "## 4.2 Moving Average Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9474d926-5bda-4ae8-b691-787e72288894",
   "metadata": {},
   "outputs": [],
   "source": [
    "moving_average = pd.Series(streamflow).rolling(window=7).mean()\n",
    "differences = np.abs(streamflow - moving_average)\n",
    "outlier_threshold = differences.mean() + 3 * differences.std()  # Define threshold for outliers\n",
    "outliers_moving_avg = np.where(differences > outlier_threshold)[0]\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(data['Date'], streamflow, label='Streamflow', color='b')\n",
    "plt.plot(data['Date'], moving_average, label='7-Day Moving Average', color='orange')\n",
    "plt.scatter(data['Date'][outliers_moving_avg], streamflow[outliers_moving_avg], color='red', label='Moving Avg Outliers', zorder=5)\n",
    "plt.title('Moving Average Method for Outlier Detection')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Streamflow (m³/s)')\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25396752-feee-474f-bb6d-6918a0826012",
   "metadata": {},
   "source": [
    "## 4.3 Density-based Methods: DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d557044-b763-412e-9d63-065d5746fa00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054d4e94-5c83-4479-8723-aae199ef1679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DBSCAN Outlier Detection\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(data[['Streamflow (m³/s)']])  # Scale the data\n",
    "\n",
    "# Fit DBSCAN (adjust eps and min_samples as needed)\n",
    "dbscan = DBSCAN(eps=0.5, min_samples=10)  # eps controls the neighborhood radius, and min_samples controls density threshold\n",
    "data['Outlier'] = dbscan.fit_predict(data_scaled)\n",
    "\n",
    "# DBSCAN labels outliers as -1, so we mark them\n",
    "dbscan_outliers = data[data['Outlier'] == -1]\n",
    "\n",
    "# Plot the time series with outliers\n",
    "plt.figure()\n",
    "plt.plot(data['Date'], data['Streamflow (m³/s)'], label='Streamflow', color='b')\n",
    "plt.plot(dbscan_outliers['Date'], dbscan_outliers['Streamflow (m³/s)'], 'ro', label='DBSCAN Detected Outliers')\n",
    "plt.title('Artificial Streamflow Time Series with Outliers and Change Point (DBSCAN Detection)')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Streamflow (m³/s)')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71356a98-fb45-405b-9ccf-c16a123fb391",
   "metadata": {},
   "source": [
    "## 5. Data Availability and Gaps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da9a5f6-3e99-4ec8-9a66-23990ce95c53",
   "metadata": {},
   "source": [
    "## 5.1 Data Availability in Time Series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740c467a-7798-4d8e-abbc-3cb0311c225b",
   "metadata": {},
   "source": [
    "### **Example 4: Large Dataset of Synthetic Time Series with Gaps**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbc0e03-9848-4e75-8e3b-2bbeb225fe31",
   "metadata": {},
   "source": [
    "We generate multiple synthetic independent time series with trend, seasonal effect, random noise AND gaps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ab6344-6991-4b12-8732-56eb758586af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate synthetic time series data\n",
    "dates = pd.date_range('2000-01-01', periods=100, freq='M')\n",
    "\n",
    "# Create a DataFrame to hold the time series\n",
    "data = pd.DataFrame(index=dates)\n",
    "\n",
    "# Generate time series\n",
    "n_series = 10\n",
    "for i in range(1, n_series + 1):  # 24 time series\n",
    "    trend = np.linspace(0, np.random.uniform(0.1, 1), len(dates))  # Linear trend\n",
    "    seasonal = 0.1 * np.sin(np.linspace(0, 3 * np.pi, len(dates)))  # Seasonal effect\n",
    "    noise = np.random.normal(loc=0, scale=0.05, size=len(dates))  # Random noise\n",
    "    series = trend + seasonal + noise  # Combine to create the time series\n",
    "    data[f'Series_{i}'] = series\n",
    "\n",
    "# Add gaps (missing values) to the series\n",
    "num_gaps = 10  # Number of NaN values to insert in each series\n",
    "for column in data.columns:\n",
    "    indices = np.random.choice(data.index, num_gaps, replace=False)  # Select random indices\n",
    "    data.loc[indices, column] = np.nan  # Assign NaN values\n",
    "\n",
    "# Plotting all the time series; highlight the last two series\n",
    "plt.figure()\n",
    "for column in data.columns:\n",
    "    plt.plot(data.index, data[column], label=column, color='blue')\n",
    "plt.title('Synthetic Time Series Data with Gaps')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Values')\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7fdeb3-f249-479f-879c-31c3d0ff669b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data for heatmap\n",
    "heatmap_data = data.notna().astype(int)  # Convert to binary (1 for available, 0 for NaN)\n",
    "heatmap_data = heatmap_data.T\n",
    "print(heatmap_data.head())\n",
    "\n",
    "# plot heatmap\n",
    "import seaborn as sns\n",
    "plt.figure()  \n",
    "sns.heatmap(availability_data.T, cmap='binary', cbar_kws={'label': 'Data Availability'}, annot=False)\n",
    "plt.title(\"Heatmap of Data Availability by Sample ID and Date\")\n",
    "plt.xlabel(\"Sample ID\")\n",
    "plt.ylabel(\"Date\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2455e267-a331-4edd-8cf3-bda6fc91f06d",
   "metadata": {},
   "source": [
    "## 5.2 Interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba178e6-5fc1-498a-9bf9-b37e2d1c662c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill the gaps using linear interpolation\n",
    "data_filled = data.interpolate(method='linear')\n",
    "\n",
    "# Plotting the original data and the filled data\n",
    "plt.figure()\n",
    "plt.plot(data_filled, label='Data after Filling', color='orange')\n",
    "plt.plot(data, label='Original Data', color='b')\n",
    "plt.title('Data with Filling Gaps')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Values')\n",
    "handles, labels = plt.gca().get_legend_handles_labels() # Create handles for the legend manually\n",
    "by_label = dict(zip(labels, handles)) # Remove duplicates by turning the labels into a set and getting unique corresponding handles\n",
    "plt.legend(by_label.values(), by_label.keys()) # Create the legend with unique entries\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d27b84-3e63-4690-9354-f3a6cb3cceb3",
   "metadata": {},
   "source": [
    "### **Example 3 [continued]: Artificial Streamflow Time Series with Outliers and Change Point**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8082d77c-a8e5-420d-969b-4a8939a10041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove outliers from the data\n",
    "filtered_streamflow = data['Streamflow (m³/s)'].copy()\n",
    "filtered_streamflow[outliers_moving_avg] = np.nan  # Set outlier points to NaN\n",
    "\n",
    "# Fill the gaps using linear interpolation\n",
    "filled_streamflow = filtered_streamflow.interpolate(method='linear')\n",
    "\n",
    "# Plotting the original data and the filled data\n",
    "plt.figure()\n",
    "plt.plot(data['Date'], data['Streamflow (m³/s)'], label='Original Streamflow', color='b')\n",
    "plt.plot(data['Date'], filled_streamflow, label='Streamflow after Outlier Removal and Filling', color='orange')\n",
    "plt.scatter(data['Date'][outliers_moving_avg], streamflow[outliers_moving_avg], color='red', label='Removed Outliers', zorder=5)\n",
    "plt.title('Streamflow Data with Outlier Removal and Filling Gaps')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Streamflow (m³/s)')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# Zooming in on one of the removed outlier points (e.g., using the first outlier)\n",
    "outlier_to_zoom = outliers_moving_avg[0]  # Choose an example outlier to zoom in\n",
    "start_date = data['Date'][outlier_to_zoom - 5]  # 5 days before\n",
    "end_date = data['Date'][outlier_to_zoom + 5]    # 5 days after\n",
    "\n",
    "# zoomed-in\n",
    "plt.figure()\n",
    "plt.plot(data['Date'], data['Streamflow (m³/s)'], label='Original Streamflow', color='b', alpha=0.5)\n",
    "plt.plot(data['Date'], filled_streamflow, label='Streamflow after Outlier Removal and Filling', color='orange')\n",
    "plt.scatter(data['Date'][outliers_moving_avg], streamflow[outliers_moving_avg], color='red', label='Removed Outliers', zorder=5)\n",
    "plt.xlim([start_date, end_date])\n",
    "plt.title('Zoomed In View Around Removed Outlier')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Streamflow (m³/s)')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63710ff8-d8b1-4dfe-a701-d724682dc8f8",
   "metadata": {},
   "source": [
    "## 5.3 Reindexing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48cdab2e-c866-4307-b9f2-388c329c3001",
   "metadata": {},
   "source": [
    "### **Example 4 [continued]: Large Dataset of Synthetic Time Series with Gaps**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a68b5f4-d12a-4988-9f5d-dcd61d50cbb5",
   "metadata": {},
   "source": [
    "## 5.3.1 Resampling\n",
    "\n",
    "For aggregating existing values over defined time interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedf1b4d-e355-48c0-a849-4ef0532ad244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use resample to get yearly mean values\n",
    "yearly_results = data.resample('Y').mean()\n",
    "\n",
    "# Example of accessing the yearly aggregated data\n",
    "print(yearly_results)\n",
    "\n",
    "# Plotting the original data and the filled data\n",
    "plt.figure()\n",
    "plt.plot(yearly_results, label='Original Data', color='b')\n",
    "plt.title('Yearly aggregated data')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Values')\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc723ee0-d038-4eb0-9647-40700d54015e",
   "metadata": {},
   "source": [
    "## 5.3.2 Interpolate & Select By Sequence\n",
    "\n",
    "Focusing on estimating values at specific times where they might not exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b632be-a00a-426f-99ba-8453312379c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "series_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298f1694-24b1-4b6c-adce-a13b4496f8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d\n",
    "\n",
    "# Sequence for interpolation (years from 2000 to 2009)\n",
    "seq_interpol = np.arange(2000, 2010, 1)\n",
    "\n",
    "# Create a new DataFrame for storing interpolated results\n",
    "yearly_results = pd.DataFrame(index=seq_interpol)\n",
    "\n",
    "# Interpolation for each column in the data DataFrame\n",
    "for column in data.columns:\n",
    "    \n",
    "    # Reset index to access Year easily for each specific series\n",
    "    series_data = data[column].reset_index()  # Create series_data inside the loop\n",
    "\n",
    "    # Rename columns for clarity\n",
    "    series_data.columns = ['Date', 'Values']\n",
    "\n",
    "    # Convert Date to its years\n",
    "    series_data['Year'] = series_data['Date'].dt.year\n",
    "    \n",
    "    # 1. Drop NaN values for interpolation\n",
    "    series_data = series_data.dropna(subset=['Values'])\n",
    "    \n",
    "    # 2. Interpolate using linear interpolation\n",
    "    # Ensure to use the 'Year' for interpolation\n",
    "    f = interp1d(series_data['Year'], series_data['Values'], \n",
    "                 kind='linear', bounds_error=False, fill_value=np.nan)\n",
    "    \n",
    "    # 3. Get interpolated values for the predefined sequence\n",
    "    interpolated_values = f(seq_interpol)\n",
    "\n",
    "    # Store interpolated values in the yearly results DataFrame\n",
    "    yearly_results[column] = interpolated_values\n",
    "\n",
    "# Example of accessing the interpolated data\n",
    "print(yearly_results)\n",
    "\n",
    "# Plotting the original data and the filled data\n",
    "plt.figure()\n",
    "plt.plot(yearly_results, label='Original Data', color='b')\n",
    "plt.title('Yearly aggregated data')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Values')\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b9786d-c817-4b41-9a93-fbcb97d27b95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
